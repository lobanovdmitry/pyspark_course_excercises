{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4b94b2e0-3796-411b-ad82-1b56e7f89e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', 0) \\\n",
    "    .config('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c2a19f1-09d4-433b-bb14-495e1f69bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+-----------+--------------------+-------+------+--------+-------------+--------------------+-----+\n",
      "|   video_id|               title|       channel_title|category_id|                tags|  views| likes|dislikes|comment_total|      thumbnail_link| date|\n",
      "+-----------+--------------------+--------------------+-----------+--------------------+-------+------+--------+-------------+--------------------+-----+\n",
      "|XpVt6Z1Gjjo|1 YEAR OF VLOGGIN...|    Logan Paul Vlogs|         24|logan paul vlog|l...|4394029|320053|    5931|        46245|https://i.ytimg.c...|13.09|\n",
      "|K4wEI5zhHB0|iPhone X — Introd...|               Apple|         28|Apple|iPhone 10|i...|7860119|185853|   26679|            0|https://i.ytimg.c...|13.09|\n",
      "|cLdxuaxaQwc|         My Response|           PewDiePie|         22|              [none]|5845909|576597|   39774|       170708|https://i.ytimg.c...|13.09|\n",
      "|WYYvHb03Eog|Apple iPhone X fi...|           The Verge|         28|apple iphone x ha...|2642103| 24975|    4542|        12829|https://i.ytimg.c...|13.09|\n",
      "|sjlHnJvXdQs|   iPhone X (parody)|          jacksfilms|         23|jacksfilms|parody...|1168130| 96666|     568|         6666|https://i.ytimg.c...|13.09|\n",
      "|cMKX2tE5Luk|The Disaster Arti...|                 A24|          1|a24|a24 films|a24...|1311445| 34507|     544|         3040|https://i.ytimg.c...|13.09|\n",
      "|8wNr-NQImFg|The Check In: HUD...|Late Night with S...|         23|Late night|Seth M...| 666169|  9985|     297|         1071|https://i.ytimg.c...|13.09|\n",
      "|_HTXMhKWqnA|iPhone X Impressi...|    Marques Brownlee|         28|iPhone X|iphone x...|1728614| 74062|    2180|        15297|https://i.ytimg.c...|13.09|\n",
      "|_ANP3HR1jsM|ATTACKED BY A POL...|    RomanAtwoodVlogs|         22|Roman Atwood|Roma...|1338533| 69687|     678|         5643|https://i.ytimg.c...|13.09|\n",
      "|zgLtEob6X-Q|Honest Trailers -...|      Screen Junkies|          1|screenjunkies|scr...|1056891| 29943|     878|         4046|https://i.ytimg.c...|13.09|\n",
      "|Ayb_2qbZHm4| Honest College Tour|        CollegeHumor|         23|Collegehumor|CH o...| 859289| 34485|     726|         1914|https://i.ytimg.c...|13.09|\n",
      "|CsdzflTXBVQ|Best Floyd Maywea...|     Awkward Puppets|         23|best floyd maywea...| 452477| 28050|     405|         2745|https://i.ytimg.c...|13.09|\n",
      "|l864IBj7cgw|Jennifer Lawrence...|The Tonight Show ...|         23|The Tonight Show|...| 258781|  8085|     303|          726|https://i.ytimg.c...|13.09|\n",
      "|4MkC65emkG4|Hand In Hand A Be...|                 MTV|         24|mtv|video|online|...| 274358|  9215|     477|          838|https://i.ytimg.c...|13.09|\n",
      "|vu_9muoxT50|Colin Cloud: Mind...|America's Got Talent|         24|America's Got Tal...| 473691| 14740|     415|         1696|https://i.ytimg.c...|13.09|\n",
      "|1L7JFN7tQLs|iPhone X Hands on...|   Jonathan Morrison|         28|Apple|iPhone X|iP...| 514972| 18936|     641|         3817|https://i.ytimg.c...|13.09|\n",
      "|ZQK1F0wz6z4|What Do You Want ...| Wong Fu Productions|         24|panda|what should...| 282858| 14870|     300|         1398|https://i.ytimg.c...|13.09|\n",
      "|T_PuZBdT2iM|getting into a co...|               ProZD|          1|skit|korean|langu...|1582683| 65749|    1531|         3598|https://i.ytimg.c...|13.09|\n",
      "|w8fAellnPns|Juicy Chicken Bre...| You Suck At Cooking|         26|how to|cooking|re...| 479951| 23945|     640|         1941|https://i.ytimg.c...|13.09|\n",
      "|UCrBICYM0yM|Downsizing (2017)...|  Paramount Pictures|          1|downsizing|previe...|2693468|  7941|     302|         1432|https://i.ytimg.c...|13.09|\n",
      "+-----------+--------------------+--------------------+-----------+--------------------+-------+------+--------+-------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videos = spark.read.option('header', 'true').option(\"inferSchema\", \"true\").csv('../datasets/USvideos.csv')\n",
    "videos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "805005cc-0c92-45e3-ab79-44a348f9c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+-------+\n",
      "|   video_id|        comment_text|likes|replies|\n",
      "+-----------+--------------------+-----+-------+\n",
      "|XpVt6Z1Gjjo|Logan Paul it's y...|    4|      0|\n",
      "|XpVt6Z1Gjjo|I've been followi...|    3|      0|\n",
      "|XpVt6Z1Gjjo|Say hi to Kong an...|    3|      0|\n",
      "|XpVt6Z1Gjjo| MY FAN . attendance|    3|      0|\n",
      "|XpVt6Z1Gjjo|         trending 😉|    3|      0|\n",
      "|XpVt6Z1Gjjo|#1 on trending AY...|    3|      0|\n",
      "|XpVt6Z1Gjjo|The end though 😭...|    4|      0|\n",
      "|XpVt6Z1Gjjo|#1 trending!!!!!!!!!|    3|      0|\n",
      "|XpVt6Z1Gjjo|Happy one year vl...|    3|      0|\n",
      "|XpVt6Z1Gjjo|You and your shit...|    0|      0|\n",
      "|XpVt6Z1Gjjo|There should be a...|    0|      0|\n",
      "|XpVt6Z1Gjjo|Dear Logan, I rea...|    0|      0|\n",
      "|XpVt6Z1Gjjo|Honestly Evan is ...|    0|      0|\n",
      "|XpVt6Z1Gjjo|Casey is still be...|    0|      0|\n",
      "|XpVt6Z1Gjjo|aw geez rick this...|    0|      0|\n",
      "|XpVt6Z1Gjjo|He happy cause he...|    0|      0|\n",
      "|XpVt6Z1Gjjo|Ayyyyoooo Logang ...|    1|      0|\n",
      "|XpVt6Z1Gjjo|Bro y didnt u giv...|    0|      0|\n",
      "|XpVt6Z1Gjjo|It's been fun wat...|    3|      0|\n",
      "|XpVt6Z1Gjjo|Made a lot of peo...|    0|      0|\n",
      "+-----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_schema = StructType([ \\\n",
    "    StructField(\"video_id\", StringType(), True), \\\n",
    "    StructField(\"comment_text\", StringType(), True), \\\n",
    "    StructField(\"likes\", IntegerType(), True), \\\n",
    "    StructField(\"replies\", IntegerType(), True)])\n",
    "comments = spark.read.option('header', 'true').option(\"mode\", \"DROPMALFORMED\").schema(comments_schema).csv('../datasets/UScomments.csv')\n",
    "comments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ffd04193-13d7-403e-97be-35f13c7a3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+-----------+--------------------+--------+------+--------+-------------+--------------------+-----+\n",
      "|   video_id|               title|       channel_title|category_id|                tags|   views| likes|dislikes|comment_total|      thumbnail_link| date|\n",
      "+-----------+--------------------+--------------------+-----------+--------------------+--------+------+--------+-------------+--------------------+-----+\n",
      "|5ggZ9jIHnr8|Alesso & Anitta -...|              Alesso|         10|alesso anitta is ...|14849524|618436|  108966|        84942|https://i.ytimg.c...|20.10|\n",
      "|7Lyo5dCig-U|BBC Anchor Gets L...|         NewsFunnies|         25|news bloopers|blo...|  273256|  2408|     121|          263|https://i.ytimg.c...|14.09|\n",
      "|B_CHjYoqPUU|Casually Explaine...|  Casually Explained|         23|is she into you|d...| 1516624| 76278|    1541|         3989|https://i.ytimg.c...|15.09|\n",
      "|Km_u51OE3VA|Mosaic: Official ...|                 HBO|          1|HBO|Sharon Stone|...|   37882|   267|      11|           19|https://i.ytimg.c...|11.10|\n",
      "|P00HMxdsVZI|Lizzo - Truth Hur...|         Lizzo Music|         10|lizzo|truth hurts...|   64963|  3036|      61|          245|https://i.ytimg.c...|29.09|\n",
      "|a6y01PSb6qU|The Strangest Sig...|          Skunk Bear|         28|cassini|nasa|satu...|  160545|  1423|      18|          143|https://i.ytimg.c...|19.09|\n",
      "|hVQPVGPAUtc|Gov. Mike Huckabe...|            Huckabee|         25|donald trump|mike...|  386745|     0|       0|            0|https://i.ytimg.c...|12.10|\n",
      "|hg5yXLhl3CQ|Charles Bukowski ...|   Alyosha Tanetović|         24|            bukowski|    6668|    77|       1|           17|https://i.ytimg.c...|20.09|\n",
      "|j-JOG2mUt0c|Stephen A. Smith ...|                ESPN|         17|stephen a. smith|...| 1137564| 14335|    1017|         5282|https://i.ytimg.c...|22.10|\n",
      "|klSWPvDCYoI|Best Friends Chal...|The Tonight Show ...|         23|The Tonight Show|...|  625564| 15712|     333|          728|https://i.ytimg.c...|20.09|\n",
      "|nQDcDZ6rmGE|Flight of the Yea...|            NURK FPV|         28|fpv|drone|fpv dro...|  939443| 10791|     445|         1438|https://i.ytimg.c...|26.09|\n",
      "|pgCtsVdK4HA|Joe Goes To The J...|            Joe Goes|         23|Juggalo March|Jug...|   48163|  2452|      81|          510|https://i.ytimg.c...|30.09|\n",
      "|rgbnZG85IRo|What Americans He...|    Associated Press|         25|affairs|america|a...|  753492|  2795|    2077|            0|https://i.ytimg.c...|19.10|\n",
      "|2wxyDrfwlXQ|What's In This 90...|       grav3yardgirl|         26|beauty|how to|mak...|  536693| 20794|     419|         3367|https://i.ytimg.c...|16.09|\n",
      "|AYrTkoRr6hk|Rep. Steve Scalis...|              C-SPAN|         25|Steve Scalise|Hou...|   11019|   288|      33|          131|https://i.ytimg.c...|30.09|\n",
      "|D3bj3PH7PGg|Eyewitness descri...|            ABC News|         25|Las Vegas shootin...|  447839|  1827|     397|         2918|https://i.ytimg.c...|04.10|\n",
      "|FTIStPerVNw|Bernie Sanders Tr...|The Late Show wit...|         24|The Late Show|Ste...| 1493731| 23472|    3490|         5872|https://i.ytimg.c...|13.09|\n",
      "|GRDoasFyesU|Trying $3000 Lace...|       Chloe Morello|         26|australian|blogge...|  112533|  4026|     174|          412|https://i.ytimg.c...|30.09|\n",
      "|LyEY0sNQIGQ|Make-Up Hater Wea...|              Boldly|         22|buzzfeed|boldly|f...| 1487634| 42158|     806|         1640|https://i.ytimg.c...|27.09|\n",
      "|MrujGOjzUI4|PREGNANT LOOKING?...|          Liza Koshy|         23|liza|lizza|lizzza...| 4989547|408649|    3149|        18257|https://i.ytimg.c...|19.10|\n",
      "+-----------+--------------------+--------------------+-----------+--------------------+--------+------+--------+-------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------------------+-----+-------+\n",
      "|   video_id|        comment_text|likes|replies|\n",
      "+-----------+--------------------+-----+-------+\n",
      "|JO7X9ZPoAp8|I thought the was...|  170|      6|\n",
      "|JO7X9ZPoAp8|i thought this wa...|    7|      0|\n",
      "|JO7X9ZPoAp8|ask people who we...|    2|      0|\n",
      "|JO7X9ZPoAp8|  Mac is the best!❤️|    2|      0|\n",
      "|JO7X9ZPoAp8|Who's watching wi...|    1|      0|\n",
      "|JO7X9ZPoAp8|When a blind pers...|    1|      0|\n",
      "|JO7X9ZPoAp8|excited to see Ma...|    2|      0|\n",
      "|JO7X9ZPoAp8|Ah ah ah Take tha...|    2|      0|\n",
      "|JO7X9ZPoAp8|Has someone told ...|    0|      0|\n",
      "|JO7X9ZPoAp8|The guy with nice...|    0|      0|\n",
      "|JO7X9ZPoAp8|Preference = Shal...|    0|      0|\n",
      "|JO7X9ZPoAp8|Thanks for sharin...|    0|      0|\n",
      "|JO7X9ZPoAp8|Can't believe my ...|    0|      0|\n",
      "|JO7X9ZPoAp8|Up next, deaf peo...|    0|      0|\n",
      "|JO7X9ZPoAp8|Lmao why did I th...|    0|      0|\n",
      "|JO7X9ZPoAp8|ask blind men how...|    0|      0|\n",
      "|JO7X9ZPoAp8|I'm listening to ...|    0|      0|\n",
      "|JO7X9ZPoAp8|the only ones pri...|    0|      0|\n",
      "|JO7X9ZPoAp8|Everyone so shock...|    0|      0|\n",
      "|JO7X9ZPoAp8|Yooo, I just uplo...|    0|      0|\n",
      "+-----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Подготовка датасетов\n",
    "# выбираем информацию по видео только за последний день\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "by_date = Window.partitionBy('video_id').orderBy(desc('date'))\n",
    "last_video_stats = videos.withColumn('row', row_number().over(by_date).alias('row'))\\\n",
    "  .where(col('row') == 1).drop(\"row\")\n",
    "\n",
    "# используем bucketing для исходных датасетов чтобы облегчить join,\n",
    "# так как partion skewing не обнаружен\n",
    "# partitioning не применим (т.к. ключ группировки 'video_id' не фиксирован)\n",
    "buckets_num = 16\n",
    "last_video_stats\\\n",
    "        .write.bucketBy(buckets_num, 'video_id')\\\n",
    "        .saveAsTable('videos', format='parquet', mode='overwrite')\n",
    "bucketed_videos = spark.sql('select * from videos')\n",
    "bucketed_videos.show()\n",
    "\n",
    "comments\\\n",
    "        .write.bucketBy(buckets_num, 'video_id')\\\n",
    "        .saveAsTable('comments', format='parquet', mode='overwrite')\n",
    "bucketed_comments = spark.sql('select * from comments')\n",
    "bucketed_comments.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "98554b7c-d1cb-4f7e-94d6-7f66b02744d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+-----------+--------------------+-------+------+--------+-------------+--------------------+-----+-------------+---------------+------------+\n",
      "|   video_id|               title|       channel_title|category_id|                tags|  views| likes|dislikes|comment_total|      thumbnail_link| date|comment_likes|comment_replies|       score|\n",
      "+-----------+--------------------+--------------------+-----------+--------------------+-------+------+--------+-------------+--------------------+-----+-------------+---------------+------------+\n",
      "|4F2KWDQQMhY|Riverdale: Betwee...|    Madelaine Petsch|         22|madelaine|madelai...| 284397| 23482|      56|         1674|https://i.ytimg.c...|18.09|           63|             22|   2376614.7|\n",
      "|4yCkkOvIkUI|EXCLUSIVE: Zonniq...|            YBF Chic|         24|              [none]|   5662|    33|      21|           13|https://i.ytimg.c...|06.10|           36|              4|      3876.2|\n",
      "|7KS2oJPzeZk|Darci Lynne and T...|America's Got Talent|         24|America's Got Tal...|4171468| 40172|    2041|         3018|https://i.ytimg.c...|26.09|          292|            111|   4416506.8|\n",
      "|7TN09IP5JuI|Terry Crews Hallu...|      First We Feast|         26|First we feast|fw...|5066207|196868|    2083|        22920|https://i.ytimg.c...|10.10|           34|              0|2.01727607E7|\n",
      "|Bo-qp-Zu0OY|Meeting Talking D...|        TouringPlans|         19|talking mickey|ta...|  21654|   179|       1|           30|https://i.ytimg.c...|30.09|           71|              8|     20490.4|\n",
      "|HYWiIWpcCIM|Do We Have Free W...|  The School of Life|         27|the school of lif...| 132374|  4924|     423|          936|https://i.ytimg.c...|22.10|           55|             51|    502192.4|\n",
      "|RE-far-FvRs|PUPPIES FIRST BAT...|          VLOGTOWSKI|         22|vlog|family vlog|...| 323280| 13781|     292|         2024|https://i.ytimg.c...|12.10|           40|              4|   1407748.0|\n",
      "|TTkzAiZ6YV0|Satisfying YO-YO ...|      Giaco Whatever|         24|yoyo|satisfying|o...|  73789|  2457|     284|          342|https://i.ytimg.c...|09.10|           43|             45|    250903.9|\n",
      "|TzyraAp3jaY|Martin Scorsese T...|         MasterClass|         27|Martin Scorsese|f...|  84257|   842|       1|           98|https://i.ytimg.c...|26.09|         1126|             48|     98725.7|\n",
      "|UJKl7ToDi20|UCF Football: Spa...|         UCF Knights|         17|UCF|UCF Knights|N...|   8812|    37|       0|            3|https://i.ytimg.c...|13.10|            8|              0|      4621.2|\n",
      "|V-_HM2bRa0E|Craig David - Hea...|      CraigDavidVEVO|         10|Craig David|Dance...| 109254|  4296|      75|          239|https://i.ytimg.c...|18.09|          173|              9|    440730.4|\n",
      "|Vh2WX2JNIFo|I SLEPT WITH A GH...|         MyLifeAsEva|         26|storytime|vlog|dr...| 754615| 49369|     803|        13531|https://i.ytimg.c...|29.09|        28814|            507|   5153471.5|\n",
      "|_oO0pd8VJjY|      Late Night Pho|              Domics|         23|domics|animation|...|1987959|150289|     921|        13857|https://i.ytimg.c...|06.10|           38|              0|1.52186759E7|\n",
      "|_r5eTelhpmQ|Darius Rucker - L...|    DariusRuckerVEVO|         10|Darius|Rucker|Lif...|  17783|  1072|      22|           68|https://i.ytimg.c...|30.09|          749|            123|    113733.3|\n",
      "|dInwVhRtN4E|Everything Wrong ...|          CinemaSins|          1|LEGO|LEGO Batman|...|2629650| 61164|    2890|         9409|https://i.ytimg.c...|26.09|           63|             13|   6350910.0|\n",
      "|eHq6ZA6uKOg|Strike Back - Mar...|ABC Television Ne...|         24|American Broadcas...|  50747|   404|     128|          112|https://i.ytimg.c...|30.09|          797|            138|     49559.7|\n",
      "|g_ekn1gjBq0|The Difference Be...|          Refinery29|         26|refinery29|refine...|   9534|   213|      10|           32|https://i.ytimg.c...|04.10|           47|             22|     22608.4|\n",
      "|nBAvUSZSEf8|Las Vegas Concert...|     ABC Action News|         25|Las Vegas|Vegas S...| 184133|   668|     128|         1916|https://i.ytimg.c...|06.10|           31|             69|     84778.3|\n",
      "|s7eVr-OUYkQ|Grateful (Officia...|   Elevation Worship|         10|Elevation Church|...|  27453|  1333|      17|           45|https://i.ytimg.c...|30.09|            3|              0|    135890.3|\n",
      "|tUXLO8Dtvq4| Most Dangerous Jobs|The Infographics ...|         27|Most Dangerous Jo...| 445638|  7781|     731|         2482|https://i.ytimg.c...|16.10|           26|              2|    815503.8|\n",
      "+-----------+--------------------+--------------------+-----------+--------------------+-------+------+--------+-------------+--------------------+-----+-------------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. scored_videos - датасет на основе файла USvideos.csv с добавлением колонки,\n",
    "# содержащей скор (показатель качества) видео. Никто не знает, как считать скор,\n",
    "# поэтому формулу предлагается придумать вам. Но она должна включать в себя просмотры,\n",
    "# лайки, дизлайки видео, лайки и дизлайки к комментариям к этому видео.\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "@pandas_udf('double')\n",
    "def video_score_udf(views: pd.Series, likes: pd.Series, dislikes: pd.Series, comment_likes: pd.Series, comment_replies: pd.Series) -> pd.Series:\n",
    "    # some 'magic' score formula\n",
    "    return views/10 + likes*100 - dislikes*10 + comment_likes*5 + comment_replies*10\n",
    "\n",
    "agg_comments = bucketed_comments\\\n",
    "                .groupby('video_id')\\\n",
    "                .agg(sum('likes').alias('comment_likes'), sum('replies').alias('comment_replies'))\n",
    "\n",
    "scored_videos = bucketed_videos.join(agg_comments, 'video_id', 'left')\\\n",
    "    .withColumn('score', video_score_udf('views', 'likes', 'dislikes', 'comment_likes', 'comment_replies'))\n",
    "scored_videos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "776467f9-82e8-421c-8c74-22450636cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|      category_title|median_score|\n",
      "+--------------------+------------+\n",
      "|              Comedy|  2514279.95|\n",
      "|       Howto & Style|   1242152.2|\n",
      "|               Music|   1062702.8|\n",
      "|      People & Blogs|   994081.15|\n",
      "|Science & Technology|   953925.45|\n",
      "|           Education|    907899.1|\n",
      "|       Entertainment|    843028.0|\n",
      "|     Travel & Events|    786572.8|\n",
      "|      Pets & Animals|    622508.6|\n",
      "|    Film & Animation|    595508.5|\n",
      "|              Gaming|    431630.9|\n",
      "|    Autos & Vehicles|    188666.5|\n",
      "|              Sports|    143808.1|\n",
      "|     News & Politics|    116656.8|\n",
      "|Nonprofits & Acti...|    46172.65|\n",
      "|               Shows|     12907.6|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. categories_score - датасет по категориям, в котором присутствуют следующие поля:\n",
    "# Название категории (не id, он непонятный для аналитиков!).\n",
    "# Медиана показателя score из датасета scored_videos по каждой категории.\n",
    "\n",
    "categories_schema = StructType([\\\n",
    "    StructField('items', ArrayType(\\\n",
    "        StructType([\\\n",
    "            StructField('id', StringType(), True),\\\n",
    "            StructField('snippet', StructType([\\\n",
    "                StructField('title', StringType(), True)\\\n",
    "            ]), True)\\\n",
    "        ]),\\\n",
    "    ), True)])\n",
    "\n",
    "categories = spark.read.option('multiline', 'true')\\\n",
    "                  .schema(categories_schema)\\\n",
    "                  .json('../datasets/US_category_id.json')\\\n",
    "                  .select(explode('items').alias('category'))\\\n",
    "                  .select(col('category.id').alias('category_id'), col('category.snippet.title').alias('category_title'))\n",
    "# categories.show()\n",
    "\n",
    "@pandas_udf(\"double\")\n",
    "def median_udf(v: pd.Series) -> float:\n",
    "    return v.median()\n",
    "\n",
    "# broadcast join здесь уместен так как категорий относительно мало, и врядли этот датасет склонен к сильному росту.\n",
    "scored_videos.select('category_id', 'score')\\\n",
    "             .groupby('category_id').agg(median_udf('score').alias('median_score'))\\\n",
    "             .join(broadcast(categories), 'category_id', 'left')\\\n",
    "             .select('category_title', 'median_score')\\\n",
    "             .sort(desc('median_score'))\\\n",
    "             .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "de46d2e9-0c8a-4783-8646-8c8fed311cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   tag|count|\n",
      "+------+-----+\n",
      "| funny|  217|\n",
      "|comedy|  163|\n",
      "|[none]|  144|\n",
      "|  2017|   93|\n",
      "| humor|   92|\n",
      "|how to|   84|\n",
      "|makeup|   77|\n",
      "| music|   74|\n",
      "|  vlog|   73|\n",
      "| video|   71|\n",
      "+------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Populat tags with scala udf took: 2.665118793025613\n",
      "+------+-----+\n",
      "|   tag|count|\n",
      "+------+-----+\n",
      "| funny|  217|\n",
      "|comedy|  163|\n",
      "|[none]|  144|\n",
      "|  2017|   93|\n",
      "| humor|   92|\n",
      "|how to|   84|\n",
      "|makeup|   77|\n",
      "| music|   74|\n",
      "|  vlog|   73|\n",
      "| video|   71|\n",
      "+------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Populat tags with scala udf took: 2.9980885009281337\n"
     ]
    }
   ],
   "source": [
    "# 3. popular_tags - датасет по самым популярным тэгам (название тэга + количество видео с этим тэгом).\n",
    "# В исходном датасете тэги лежат строкой в поле tags. Другие разработчики уже сталкивались с подобной задачей,\n",
    "# поэтому написали Scala-функцию для разбиения тегов. Но не доверяйте им вслепую!\n",
    "# Обязательно напишите свою функцию разбиения строки на тэги и сравните время работы с её Scala-версией.\n",
    "# Можно замерять своими силами, а можно воспользоваться библиотекой timeit.\n",
    "from pyspark.sql.column import Column, _to_java_column, _to_seq\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from timeit import Timer\n",
    "\n",
    "def split_tags_scala(col):\n",
    "    sc = spark.sparkContext\n",
    "    _split_tags_udf = sc._jvm.CustomUDFs.splitTagsUDF()\n",
    "    return Column(_split_tags_udf.apply(_to_seq(sc, [col], _to_java_column)))\n",
    "\n",
    "popular_tags_scala = bucketed_videos\\\n",
    "                          .select(split_tags_scala('tags').alias('tags'))\\\n",
    "                          .select(explode('tags').alias('tag'))\\\n",
    "                          .groupby('tag')\\\n",
    "                          .count()\\\n",
    "                          .sort(desc('count'))\n",
    "\n",
    "scala_udf_timer = Timer(lambda: popular_tags_scala.show(10))\n",
    "print('Populat tags with scala udf took: ' + str(scala_udf_timer.timeit(number=1)))\n",
    "\n",
    "\n",
    "@pandas_udf('array<string>')\n",
    "def split_tags_pandas(v: pd.Series) -> pd.Series:\n",
    "    return v.apply(lambda tags: tags.split('|'))\n",
    "\n",
    "popular_tags_pandas = bucketed_videos\\\n",
    "                           .select(split_tags_pandas('tags').alias('tags'))\\\n",
    "                           .select(explode('tags').alias('tag'))\\\n",
    "                           .groupby('tag')\\\n",
    "                           .count()\\\n",
    "                           .sort(desc('count'))\n",
    "\n",
    "pandas_udf_timer = Timer(lambda: popular_tags_pandas.show(10))\n",
    "print('Populat tags with scala udf took: ' + str(pandas_udf_timer.timeit(number=1)))\n",
    "\n",
    "# Локальные запуски показывают незначительное оставание по времени реализации на pandas (5-10%)\n",
    "# Нативную скала реализацию сложно обогнать, так как scala udf выполняется в той же самой jvm воркера\n",
    "# Pandas реализация особо не уступает так как используется ArrowEvalPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e2ab5a9b-4d8e-4e84-9b9f-175c2923a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mmh3 in /opt/conda/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: bitarray in /opt/conda/lib/python3.11/site-packages (2.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir mmh3 bitarray\n",
    "\n",
    "import math\n",
    "import mmh3\n",
    "from bitarray import bitarray\n",
    "\n",
    "class BloomFilter(object):\n",
    "  \n",
    "    '''\n",
    "    Class for Bloom filter, using murmur3 hash function\n",
    "    '''\n",
    "  \n",
    "    def __init__(self, items_count, fp_prob):\n",
    "        '''\n",
    "        items_count : int\n",
    "            Number of items expected to be stored in bloom filter\n",
    "        fp_prob : float\n",
    "            False Positive probability in decimal\n",
    "        '''\n",
    "        self.items_count = items_count\n",
    "        \n",
    "        # False possible probability in decimal\n",
    "        self.fp_prob = fp_prob\n",
    "  \n",
    "        # Size of bit array to use\n",
    "        self.size = self.get_size(items_count, fp_prob)\n",
    "  \n",
    "        # number of hash functions to use\n",
    "        self.hash_count = self.get_hash_count(self.size, items_count)\n",
    "  \n",
    "        # Bit array of given size\n",
    "        self.bit_array = bitarray(self.size)\n",
    "  \n",
    "        # initialize all bits as 0\n",
    "        self.bit_array.setall(0)\n",
    "  \n",
    "    def add(self, item):\n",
    "        '''\n",
    "        Add an item in the filter\n",
    "        '''\n",
    "        digests = []\n",
    "        for i in range(self.hash_count):\n",
    "  \n",
    "            # create digest for given item.\n",
    "            # i work as seed to mmh3.hash() function\n",
    "            # With different seed, digest created is different\n",
    "            digest = mmh3.hash(item, i) % self.size\n",
    "            digests.append(digest)\n",
    "  \n",
    "            # set the bit True in bit_array\n",
    "            self.bit_array[digest] = True\n",
    "        \n",
    "    def union(self, other):\n",
    "        \"\"\" Calculates the union of the two underlying bitarrays and returns\n",
    "        a new bloom filter object.\"\"\"\n",
    "        new_bloom = self.copy()\n",
    "        new_bloom.bit_array = new_bloom.bit_array | other.bit_array\n",
    "        return new_bloom\n",
    "  \n",
    "    def check(self, item):\n",
    "        '''\n",
    "        Check for existence of an item in filter\n",
    "        '''\n",
    "        for i in range(self.hash_count):\n",
    "            digest = mmh3.hash(item, i) % self.size\n",
    "            if self.bit_array[digest] == False:\n",
    "  \n",
    "                # if any of bit is False then,its not present\n",
    "                # in filter\n",
    "                # else there is probability that it exist\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"Return a copy of this bloom filter.\n",
    "        \"\"\"\n",
    "        new_filter = BloomFilter(self.items_count, self.fp_prob)\n",
    "        new_filter.bit_array = self.bit_array.copy()\n",
    "        return new_filter\n",
    "    \n",
    "    def set_bit_array(self, bit_array):\n",
    "        self.bit_array = bit_array\n",
    "  \n",
    "    @classmethod\n",
    "    def get_size(self, n, p):\n",
    "        '''\n",
    "        Return the size of bit array(m) to used using\n",
    "        following formula\n",
    "        m = -(n * lg(p)) / (lg(2)^2)\n",
    "        n : int\n",
    "            number of items expected to be stored in filter\n",
    "        p : float\n",
    "            False Positive probability in decimal\n",
    "        '''\n",
    "        m = -(n * math.log(p))/(math.log(2)**2)\n",
    "        return int(m)\n",
    "  \n",
    "    @classmethod\n",
    "    def get_hash_count(self, m, n):\n",
    "        '''\n",
    "        Return the hash function(k) to be used using\n",
    "        following formula\n",
    "        k = (m/n) * lg(2)\n",
    "  \n",
    "        m : int\n",
    "            size of bit array\n",
    "        n : int\n",
    "            number of items expected to be stored in filter\n",
    "        '''\n",
    "        k = (m/n) * math.log(2)\n",
    "        return int(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ba49a-94d5-46f4-9df7-b2de34dd970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И личная просьба от Марка: он любит котов (а кто не их не любит!)\n",
    "# и хочет найти самые интересные комментарии (топ-5) к видео про котов.\n",
    "# “Видео про котов” - видео, у которого есть тэг “cat\n",
    "\n",
    "videos_with_cats = bucketed_videos.where(col('tags').contains('Cat'))\n",
    "\n",
    "# будем использовать фильтр Блума для того что отфильтровать комментарии по video_id перед тем как joinить\n",
    "filterSize = 1000\n",
    "prob = 0.1\n",
    "\n",
    "def fill_bloom_filter(bf, items) -> BloomFilter:\n",
    "    for i in items:\n",
    "        bf.add(str(i['video_id']))\n",
    "    return bf\n",
    "\n",
    "bloom_filter = BloomFilter(filterSize, prob)\n",
    "\n",
    "# наполняем фильтр\n",
    "general_bit_array = videos_with_cats.select('video_id').rdd\\\n",
    "    .mapPartitions(lambda part: [fill_bloom_filter(BloomFilter(filterSize, prob), part).bit_array]) \\\n",
    "    .reduce(lambda a, b: a | b)\n",
    "\n",
    "bloom_filter.set_bit_array(general_bit_array)\n",
    "\n",
    "# создаем udf на основе фильтра\n",
    "maybe_in_bf = udf(lambda video_id: bloom_filter.check(str(video_id)))\n",
    "\n",
    "# joinим\n",
    "bucketed_comments\\\n",
    "    .where(maybe_in_bf(col('video_id')) == True) \\\n",
    "    .join(videos_with_cats, 'video_id') \\\n",
    "    .sort(desc(bucketed_comments.likes))\\\n",
    "    .limit(5)\\\n",
    "    .select(bucketed_videos.title, bucketed_comments.likes, bucketed_videos.views, bucketed_comments.comment_text)\\\n",
    "    .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
